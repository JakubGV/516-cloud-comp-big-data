Hello world, I would like to share some thoughts with you and the rest of the world.
I study Spark and also Hadoop
I prefer Spark to Hadoop
But I have to spend many more hours studying Spark
Hadoop is very difficult to compile and debug some say.
It used to make the world go round though.
But I am very interested in MapReduce which is part of Hadoop
So what shall I choose
Perhaps I can compromise let's forget about it all and do SQL
But I am studying Cloud Computing
I am supposed to get familiar with Spark Hadoop NoSQL PigHive Cassandra 
and much much more
Oh forget it. I'll only do Hadoop as this is how it all started. It is not the end of the world.
Hello world, wait for me!
No, don't I want to be more modern? Then I'd better study Spark.
Then welcome to a brand new world.